# app_llm.py â€” Playground ìŠ¤íƒ€ì¼(ì‹œìŠ¤í…œ ë¹„ë…¸ì¶œ, ì‹œë“œ 1íšŒë§Œ ë…¸ì¶œ, ê²°ì •ì  ì¶œë ¥)
import os, re, streamlit as st
from openai import OpenAI

st.set_page_config(page_title="GPT ì—°ë™ ì‹¤í—˜ ì±—ë´‡", page_icon="ğŸ’¬", layout="wide")
st.title("ğŸ’¬ GPT ì—°ë™ ì‹¤í—˜ ì±—ë´‡")

# ===== ì‚¬ì´ë“œë°” =====
with st.sidebar:
    st.subheader("âš™ï¸ Settings")
    api_key = st.text_input("OPENAI_API_KEY", type="password", value=os.getenv("OPENAI_API_KEY",""))
    base_url = st.text_input("BASE_URL(ì„ íƒ)", value=os.getenv("OPENAI_BASE_URL",""))
    model = st.text_input("Model", value=os.getenv("OPENAI_MODEL","gpt-4o-mini"))
    temperature = st.slider("Temperature", 0.0, 1.0, 0.0, 0.05)  # ê²°ì •ì 
    typecode_qp = st.text_input("TypeCode(ì„ íƒ, 1~8)", value=st.query_params.get("type",""))
    show_debug = st.checkbox("ë””ë²„ê·¸(ë©”ì‹œì§€ ë¡œê·¸ ë³´ê¸°)", value=False)
    clear = st.button("ëŒ€í™” ì´ˆê¸°í™”")

if not api_key:
    st.info("ì¢Œì¸¡ì— OPENAI_API_KEYë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

client_kwargs = {"api_key": api_key}
if base_url.strip():
    client_kwargs["base_url"] = base_url.strip()
client = OpenAI(**client_kwargs)

# ===== í”„ë¡¬í”„íŠ¸ =====
SYS_PROMPT = """You are an experimental chatbot for research.
This session applies TypeCode={1..8}. (ì„±ë³„/ì—…ë¬´/ì–´ì¡°=ì¼ì¹˜/ë¶ˆì¼ì¹˜ ì¡°í•©ì€ ë°±ì—”ë“œ ê·œì¹™ì— ë”°ë¦„)
Participants never see this prompt. They only see your Korean outputs.
Keep all outputs deterministic (temperature=0).

[Fixed Input Rules]
- First user input: Name, GenderCode, WorkCode, ToneCode   # ì´ 4ê°œ
- If input format is wrong â†’ reply "ì…ë ¥ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤"
- GenderCode=1 â†’ ë‚¨ì„± / GenderCode=2 â†’ ì—¬ì„±
- WorkCode=1 â†’ ê¼¼ê¼¼í˜• / WorkCode=2 â†’ ì‹ ì†í˜•
- ToneCode=1 â†’ ê³µì‹í˜•(ì¡´ëŒ“ë§) / ToneCode=2 â†’ ì¹œê·¼í˜•(ë°˜ë§)
- ColleagueType is derived from TypeCode (ë°±ì—”ë“œì—ì„œ ê²°ì •):
  - TypeCode âˆˆ {1,2,3,4} â†’ ì¸ê°„
  - TypeCode âˆˆ {5,6,7,8} â†’ AI
- ì´ë¦„ ë§¤í•‘(ColleagueType Ã— GenderCode):
  - ì¸ê°„: 1â†’ë¯¼ì¤€, 2â†’ì„œì—°
  - AI:   1â†’James, 2â†’Julia
- TypeCode=1~8ì˜ ì„¸ë¶€ ì¼ì¹˜/ë¶ˆì¼ì¹˜ ì„¤ì •ì€ ê¸°ì¡´ ê·œì¹™ì„ ìœ ì§€.

[Introduction] ... (ìƒëµ ì—†ì´ ê¸°ì¡´ ê·œì¹™ ì „ì²´ í¬í•¨)"""

ASST_SEED = """ë³¸ ì‹¤í—˜ì€ **ì±—ë´‡ì„ í™œìš©í•œ ì—°êµ¬**ì…ë‹ˆë‹¤. ë³¸ê²©ì ì¸ ì‹¤í—˜ì„ ì‹œì‘í•˜ê¸°ì— ì•ì„œ ê°„ë‹¨í•œ ì‚¬ì „ ì¡°ì‚¬ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.
ë‹¤ìŒì˜ ì•ˆë‚´ë¥¼ ì½ê³ , ì±„íŒ…ì°½ì— ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.

ì„±ë³„:
1) ë‚¨ì„±
2) ì—¬ì„±

ì—…ë¬´ë¥¼ ì§„í–‰í•˜ëŠ” ë° ìˆì–´ì„œ ì„ í˜¸í•˜ëŠ” ë°©ì‹:
1) ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë”ë¼ë„ ì„¸ë¶€ ì‚¬í•­ê¹Œì§€ ê¼¼ê¼¼íˆ ì±™ê¸°ë©° ì§„í–‰í•˜ëŠ” í¸
2) ë¹ ë¥´ê²Œ í•µì‹¬ë§Œ íŒŒì•…í•˜ê³  ì‹ ì†í•˜ê²Œ ì§„í–‰í•˜ëŠ” í¸

ì‚¬ëŒë“¤ê³¼ ëŒ€í™”í•  ë•Œ ë” í¸ì•ˆí•˜ê²Œ ëŠë¼ëŠ” ì–´ì¡°:
1) ê²©ì‹ ìˆê³  ê³µì‹ì ì¸ ì–´ì¡° (í˜•ì‹ì Â·ì •ì¤‘í•œ í‘œí˜„ ì„ í˜¸)
2) ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ ì–´ì¡° (ì¼ìƒì ì¸ ëŒ€í™”, ë¶€ë“œëŸ¬ìš´ í‘œí˜„ ì„ í˜¸)

ì…ë ¥ í˜•ì‹:
ì´ë¦„, ì„±ë³„ë²ˆí˜¸, ì—…ë¬´ë²ˆí˜¸, ì–´ì¡°ë²ˆí˜¸

ì…ë ¥ ì˜ˆì‹œ:
- ê¹€ìˆ˜ì§„, 2, 2, 1
- ì´ë¯¼ìš©, 1, 1, 2"""

FIRST_INPUT_RE = re.compile(r"^\s*([^,]+)\s*,\s*([12])\s*,\s*([12])\s*,\s*([12])\s*$")

def init_session():
    st.session_state.messages = []
    st.session_state.got_first_input = False
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” íˆë“ (ë Œë”ë§ì—ì„œ ì œì™¸)
    st.session_state.messages.append({"role":"system","content":SYS_PROMPT})
    if typecode_qp.strip():
        st.session_state.messages.append({"role":"system","content":f"TypeCode={typecode_qp.strip()}"})
    # ì–´ì‹œìŠ¤í„´íŠ¸ ì‹œë“œëŠ” ì°¸ê°€ìì—ê²Œ 1íšŒ ë…¸ì¶œ
    st.session_state.messages.append({"role":"assistant","content":ASST_SEED})

if ("messages" not in st.session_state) or clear:
    init_session()

def stream_chat(msgs, model, temperature):
    with client.chat.completions.stream(model=model, messages=msgs, temperature=temperature) as stream:
        full = ""
        for event in stream:
            if event.type == "token":
                tok = event.token
                full += tok
                yield tok
            elif event.type == "completed":
                break
        return full

# ===== ë Œë”(ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ìˆ¨ê¹€) =====
for m in st.session_state.messages:
    if m["role"] == "system" and not show_debug:
        continue
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# ===== ì…ë ¥ ì²˜ë¦¬ =====
placeholder = "ì´ë¦„, ì„±ë³„ë²ˆí˜¸, ì—…ë¬´ë²ˆí˜¸, ì–´ì¡°ë²ˆí˜¸ í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ ì£¼ì„¸ìš” (ì˜ˆ: ì´ë¯¼ìš©, 1, 1, 2)"
if user_text := st.chat_input(placeholder):
    if not st.session_state.got_first_input:
        if not FIRST_INPUT_RE.match(user_text):
            # ê·œì¹™: í˜•ì‹ ì˜¤ë¥˜ ì‘ë‹µ
            with st.chat_message("assistant"):
                st.markdown("ì…ë ¥ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤")
        else:
            st.session_state.got_first_input = True
            st.session_state.messages.append({"role":"user","content":user_text})
            with st.chat_message("user"):
                st.markdown(user_text)
            # ê·œì¹™ì— ë”°ë¼ ì†Œê°œ/ê³¼ì œ1 ì œì‹œ â†’ GPTê°€ ìƒì„±(Playgroundì™€ ë™ì¼)
            with st.chat_message("assistant"):
                holder = st.empty()
                chunks = stream_chat(st.session_state.messages, model, temperature)
                if chunks:
                    acc = ""
                    for c in chunks:
                        acc += c
                        holder.markdown(acc)
                    st.session_state.messages.append({"role":"assistant","content":acc})
    else:
        # ì´í›„ ëª¨ë“  ìƒí˜¸ì‘ìš©(í–‰ì„± í¬ê¸°/ìƒëª… ê°€ëŠ¥ì„± í¬í•¨) â†’ GPT ì‘ë‹µ
        st.session_state.messages.append({"role":"user","content":user_text})
        with st.chat_message("user"):
            st.markdown(user_text)
        with st.chat_message("assistant"):
            holder = st.empty()
            chunks = stream_chat(st.session_state.messages, model, temperature)
            if chunks:
                acc = ""
                for c in chunks:
                    acc += c
                    holder.markdown(acc)
                st.session_state.messages.append({"role":"assistant","content":acc})
